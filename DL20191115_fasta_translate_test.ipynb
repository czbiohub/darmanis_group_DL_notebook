{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, subprocess, mygene\n",
    "import pandas as pd\n",
    "\n",
    "def translate(seq, frame=1): \n",
    "    # frame: 1 = start at pos 0; 2 = start at pos 1; 3 = start at pos 2\n",
    "    table = { \n",
    "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M', \n",
    "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T', \n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K', \n",
    "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',                  \n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L', \n",
    "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P', \n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q', \n",
    "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R', \n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V', \n",
    "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A', \n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E', \n",
    "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G', \n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S', \n",
    "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L', \n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'', 'TAG':'', \n",
    "        'TGC':'C', 'TGT':'C', 'TGA':'', 'TGG':'W', \n",
    "    } \n",
    "    comp_dict = {'C':'G',\n",
    "                 'G':'C',\n",
    "                 'A':'T',\n",
    "                 'T':'A'\n",
    "                }\n",
    "    protein = ''\n",
    "    \n",
    "    if frame == 1 :\n",
    "        start_val = 0\n",
    "    if frame == 2:\n",
    "        start_val = 1\n",
    "    if frame == 3:\n",
    "        start_val = 2\n",
    "    if frame == 4 :\n",
    "        start_val = 0\n",
    "    if frame == 5:\n",
    "        start_val = 1\n",
    "    if frame == 6:\n",
    "        start_val = 2\n",
    "    if frame > 3:\n",
    "        seq = ''.join([comp_dict.get(x) for x in seq])\n",
    "        \n",
    "    for i in range(start_val, len(seq), 3): \n",
    "        try:\n",
    "            codon = seq[i:i + 3] \n",
    "            protein+= table[codon] \n",
    "        except:\n",
    "            break\n",
    "    return protein\n",
    "\n",
    "def split_translation (full_seq, len_cutoff = 10):\n",
    "    sub_seq = [x for x in full_seq.split('_') if len(x) > len_cutoff]\n",
    "    return sub_seq\n",
    "\n",
    "def print_fasta (sub_list, prefix='test'):\n",
    "    for idx, entry in enumerate(sub_list):\n",
    "        print(f'>{prefix}_{idx}\\n{entry}')\n",
    "        \n",
    "def save_fasta (sub_list, prefix, output):\n",
    "    with open(output, 'w') as f:\n",
    "        for idx, entry in enumerate(sub_list):\n",
    "            line = f'>{prefix}_{idx}\\n{entry}\\n'\n",
    "            f.write(line)\n",
    "            \n",
    "def process_fasta (infile, frames, outfile):\n",
    "    with open(infile, 'r') as f:\n",
    "        sublines = []\n",
    "        entry_name = ''\n",
    "        for idx,line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if line.startswith('>') and entry_name == '':\n",
    "                entry_name = line\n",
    "            if line.startswith('>') and entry_name != '':\n",
    "                if len(sublines) > 0:\n",
    "                    print_seq = ''.join(sublines)\n",
    "                    ### process entry seq\n",
    "                    with open(outfile, 'a') as outf:\n",
    "                        for frame in frames:\n",
    "                            full_seq = translate(print_seq, frame)\n",
    "                            outf.write(f'{entry_name}__fr_{frame}\\n{full_seq}\\n')\n",
    "                    ###\n",
    "                    sublines = []\n",
    "                entry_name = line\n",
    "            else:\n",
    "                sublines = sublines+[line]                          \n",
    "        if len(sublines) > 0:\n",
    "            print_seq = ''.join(sublines)\n",
    "            ### process entry seq\n",
    "            with open(outfile, 'a') as outf:\n",
    "                for frame in frames:\n",
    "                    full_seq = translate(print_seq, frame)\n",
    "                    outf.write(f'{entry_name}__fr_{frame}\\n{full_seq}\\n')\n",
    "            ###\n",
    "            sublines = []\n",
    "            \n",
    "\n",
    "# ingest uniprot to symbol df for lookup\n",
    "uniprot2symbol_df = pd.read_csv('/home/ubuntu/data/longread/proteome/uniprot2symbol.csv',\n",
    "                               index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-17000...done.\n",
      "querying 17001-18000...done.\n",
      "querying 18001-19000...done.\n",
      "querying 19001-20000...done.\n",
      "querying 20001-20659...done.\n",
      "Finished.\n",
      "359 input query terms found dup hits:\n",
      "\t[('A0A075B6J1', 2), ('A0A075B6J2', 2), ('A0A075B6P5', 2), ('A0A075B6Q5', 2), ('A0A075B6R2', 2), ('A0\n",
      "1176 input query terms found no hit:\n",
      "\t['A0A075B734', 'A0A075B767', 'A0A075B7B9', 'A0A075B7E0', 'A0A087WSY4', 'A0A087WUL8', 'A0A087WVI0', '\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "# # ingest uniprot proteome\n",
    "# proteome_fasta = '/home/ubuntu/data/longread/proteome/UP000005640_9606.fasta'\n",
    "# uniprot_list = []\n",
    "# with open(proteome_fasta, 'r') as f:\n",
    "#     for idx,line in enumerate(f):\n",
    "#         line = line[:-1]\n",
    "#         if line.startswith('>'):\n",
    "#             # extract uniprot id field\n",
    "#             line_split = line.split('|')[1]\n",
    "#             uniprot_list = uniprot_list+[line_split]\n",
    "\n",
    "# # query for gene symbols\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# uniprot2symbol_df = mg.querymany(uniprot_list, \n",
    "#                                    scopes='uniprot', \n",
    "#                                    fields='symbol', \n",
    "#                                    species='human',\n",
    "#                                    returnall=False,\n",
    "#                                    as_dataframe=True\n",
    "#                                   )\n",
    "\n",
    "# # filter and save results\n",
    "# uniprot2symbol_df = uniprot2symbol_df[uniprot2symbol_df.notfound != True]\n",
    "# uniprot2symbol_df = (uniprot2symbol_df\n",
    "#                      .reset_index()\n",
    "#                      .loc[:, ['query','symbol']]\n",
    "#                      .rename(columns = {'query':'uniprot'})\n",
    "#                      .dropna()\n",
    "#                     )\n",
    "# uniprot2symbol_df.to_csv('/home/ubuntu/data/longread/proteome/uniprot2symbol.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing results subdir\n",
      "created results subdir\n",
      "translated to protein\n",
      "blastp -query /home/ubuntu/data/longread/blast_results/A10_TSO1/A10_TSO1_protein.fa -db /home/ubuntu/data/longread/proteome/UP000005640_9606.fasta -outfmt \"6 qseqid sseqid evalue\" -max_target_seqs 1 -out /home/ubuntu/data/longread/blast_results/A10_TSO1/A10_TSO1_blastp_out.txt -num_threads 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = '/home/ubuntu/data/longread/blast_results/'\n",
    "target_path = '/home/ubuntu/data/longread/A10_TSO1.fa'\n",
    "target_suffix = '.fa'\n",
    "cell_id = target_path.split('/')[-1].split(target_suffix)[0]\n",
    "frames = [1,2,3]\n",
    "proteome_ref = '/home/ubuntu/data/longread/proteome/UP000005640_9606.fasta'\n",
    "n_threads = 4\n",
    "\n",
    "# create results subdir\n",
    "try:\n",
    "    shutil.rmtree(f'{results_dir}{cell_id}')\n",
    "    print('deleted existing results subdir')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(f'{results_dir}{cell_id}')\n",
    "    print('created results subdir')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# translate nucl to prot\n",
    "process_fasta(f'{target_path}', \n",
    "              frames,\n",
    "              f'{results_dir}{cell_id}/{cell_id}_protein.fa'\n",
    "             )\n",
    "print('translated to protein')\n",
    "\n",
    "# run blast\n",
    "blast_cmd_list = ['blastp',\n",
    "                  '-query',\n",
    "                  f'{results_dir}{cell_id}/{cell_id}_protein.fa',\n",
    "                  '-db',\n",
    "                  proteome_ref,\n",
    "                  '-outfmt',\n",
    "                  '\"6 qseqid sseqid evalue\"',\n",
    "                  '-max_target_seqs',\n",
    "                  '1',\n",
    "                  '-out',\n",
    "                  f'{results_dir}{cell_id}/{cell_id}_blastp_out.txt',\n",
    "                  '-num_threads',\n",
    "                  f'{n_threads}'\n",
    "                 ]\n",
    "blast_cmd = ' '.join(blast_cmd_list)\n",
    "print(blast_cmd)\n",
    "subprocess.call(blast_cmd, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('/home/ubuntu/data/longread/blast_results/A10_TSO1/A10_TSO1_blastp_out.txt', \n",
    "                      sep = '\\t',\n",
    "                      header = None\n",
    "                     )\n",
    "results.columns = ['qsid' , 'ssid', 'evalue']\n",
    "results['frame'] = [x.split('__')[-1][-1] for x in results['qsid']]\n",
    "results['qsid'] = [x.split('__')[0] for x in results['qsid']]\n",
    "results['uniprot_id'] = [x.split('|')[1] for x in results['ssid']]\n",
    "results['common_name'] = [x.split('|')[2] for x in results['ssid']]\n",
    "results = results.sort_values('evalue', ascending = True).groupby(['qsid']).head(1)\n",
    "results = pd.DataFrame(results['uniprot_id'].value_counts())\n",
    "results = (results\n",
    "           .reset_index()\n",
    "           .rename(columns={'index':'uniprot',\n",
    "                            'uniprot_id':'count'\n",
    "                           })\n",
    "          )\n",
    "results = pd.merge(uniprot2symbol_df,\n",
    "                   results,\n",
    "                   'left',\n",
    "                   'uniprot'\n",
    "                  )\n",
    "results = results.drop('uniprot', axis=1)\n",
    "results['count'] = (results['count']\n",
    "                    .replace(np.nan, 0)\n",
    "                    .astype(int)\n",
    "                    .dropna()\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Z82206.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NUDT4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TRBV20OR9-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>IGKV3-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IGKV1D-42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19954</td>\n",
       "      <td>LSM4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19955</td>\n",
       "      <td>AL034430.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19956</td>\n",
       "      <td>SPACA6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19957</td>\n",
       "      <td>PYDC5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19958</td>\n",
       "      <td>HLA-DRB4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19959 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            symbol  count\n",
       "0         Z82206.1      0\n",
       "1            NUDT4      0\n",
       "2      TRBV20OR9-2      0\n",
       "3          IGKV3-7      0\n",
       "4        IGKV1D-42      0\n",
       "...            ...    ...\n",
       "19954         LSM4      0\n",
       "19955   AL034430.1      0\n",
       "19956       SPACA6      0\n",
       "19957        PYDC5      0\n",
       "19958     HLA-DRB4      0\n",
       "\n",
       "[19959 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalize file names to stream many cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
